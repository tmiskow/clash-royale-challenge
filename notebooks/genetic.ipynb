{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic search approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.load('../data/train_X.npy')\n",
    "train_y = np.load('../data/train_y.npy')\n",
    "valid_X = np.load('../data/valid_X.npy')\n",
    "valid_y = np.load('../data/valid_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1500  # dataset size\n",
    "T = 16  # number of datasets per generation\n",
    "M = 0.2  # fraction of dataset samples dropped during mutation phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class DataSet(object):\n",
    "    X: np.array\n",
    "    y: np.array\n",
    "    ids: np.array\n",
    "    \n",
    "    @classmethod\n",
    "    def combine(cls, ds1, ds2):\n",
    "        assert(ds1.X.shape == ds2.X.shape)\n",
    "        intersection = np.intersect1d(ds1.ids, ds2.ids)\n",
    "        other = np.random.choice(\n",
    "            np.setxor1d(ds1.ids, ds2.ids), len(ds1.ids)-len(intersection)\n",
    "        )\n",
    "        new_ids = np.concatenate([intersection, other])\n",
    "        take_from_left = np.isin(ds1.ids, new_ids)\n",
    "        take_from_right = np.isin(ds2.ids, new_ids)\n",
    "        # new ids need to be re-ordered to match the order \n",
    "        # in which X and y are selected for the new DataSet:\n",
    "        new_ids = np.select(\n",
    "            [take_from_left, take_from_right],\n",
    "            [ds1.ids, ds2.ids]\n",
    "        )\n",
    "        new_X = np.select(\n",
    "            [\n",
    "                np.repeat(take_from_left, ds1.X.shape[1]).reshape(ds1.X.shape),\n",
    "                np.repeat(take_from_right, ds2.X.shape[1]).reshape(ds2.X.shape)\n",
    "            ],\n",
    "            [ds1.X, ds2.X]\n",
    "        )\n",
    "        new_y = np.select(\n",
    "            [take_from_left, take_from_right],\n",
    "            [ds1.y, ds2.y]\n",
    "        )\n",
    "        return cls(new_X, new_y, new_ids)\n",
    "        \n",
    "\n",
    "def sample_datasets(\n",
    "        n_samples: int=N, \n",
    "        n_datasets: int=T, \n",
    "        n_validation_samples: int=10*N, \n",
    "        source_X: np.array=train_X, \n",
    "        source_y: np.array=train_y\n",
    ") -> Tuple[List[DataSet], DataSet]:\n",
    "    ids = [\n",
    "        np.random.choice(\n",
    "            len(source_X), \n",
    "            n_samples, \n",
    "            replace=False\n",
    "        ) for i in range(n_datasets)\n",
    "    ]\n",
    "    rest_ids = np.array(list(set(range(len(source_X))) - set(list(np.concatenate(ids)))))\n",
    "    validation_ids = np.random.choice(rest_ids, n_validation_samples)\n",
    "    return [DataSet(source_X[i], source_y[i], i) for i in ids], DataSet(source_X[validation_ids], source_y[validation_ids], validation_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "params_dict = {\n",
    "    'kernel': ['rbf'],\n",
    "    'gamma': [1 / i for i in range(80, 130, 10)],\n",
    "    'C': [0.9, 1.0, 1.1],\n",
    "    'epsilon': [1e-3, 3e-3, 1e-2, 3e-2, 1e-1, 3e-1],\n",
    "    'shrinking': [True]\n",
    "}\n",
    "\n",
    "def train_svr(train_set: DataSet, param_validation_set: DataSet, params_dict: dict=params_dict, n_iter: int=25):\n",
    "    ps = ParameterSampler(n_iter=n_iter, param_distributions=params_dict)\n",
    "    scores = np.zeros(n_iter)\n",
    "    models = list()\n",
    "    for idx, params in enumerate(ps):\n",
    "        svr = SVR(**params)\n",
    "        svr.fit(train_set.X, train_set.y)\n",
    "        preds = svr.predict(param_validation_set.X)\n",
    "        scores[idx] = r2_score(param_validation_set.y, preds)\n",
    "        models.append(svr)\n",
    "    return models[np.argmax(scores)]\n",
    "\n",
    "def _train_one(tupl):\n",
    "    ds, param_validation_set = tupl\n",
    "    return train_svr(ds, param_validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_probabilities(weighted_sample_scores):\n",
    "    # must modify sample scores to be nonnegative\n",
    "    modified_sample_scores = np.exp(weighted_sample_scores)\n",
    "    inversed_sample_scores = 1 / modified_sample_scores\n",
    "    normalised_sample_scores = inversed_sample_scores / inversed_sample_scores.sum()\n",
    "    # cut useless datasamples\n",
    "    sorted_ids = np.argsort(normalised_sample_scores)\n",
    "    cum_sum = np.cumsum(normalised_sample_scores[sorted_ids])\n",
    "    to_zero_out_ids = sorted_ids[cum_sum < 0.5]\n",
    "    normalised_sample_scores[to_zero_out_ids] = 0\n",
    "    \n",
    "    renormalised_sample_scores = normalised_sample_scores / normalised_sample_scores.sum()\n",
    "    return renormalised_sample_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "from math import ceil\n",
    "from multiprocessing import Pool, Array\n",
    "\n",
    "class VerboseMixin(object):\n",
    "    def _progress(self, iterator, total):\n",
    "        if self.verbose:\n",
    "            return tqdm(iterator, total=total, desc=self.__class__.__name__)\n",
    "        else:\n",
    "            return iterator\n",
    "\n",
    "    def _log(self, message):\n",
    "        if self.verbose:\n",
    "            print(f\"[{self.__class__.__name__}] {message}\")\n",
    "\n",
    "class Evolution(VerboseMixin):\n",
    "    def __init__(\n",
    "            self, \n",
    "            T=T, \n",
    "            M=M,\n",
    "            train_X=train_X, \n",
    "            train_y=train_y, \n",
    "            valid_X=valid_X, \n",
    "            valid_y=valid_y, \n",
    "            n_generations: int=100,\n",
    "            n_workers: int=4,\n",
    "            verbose: bool=False\n",
    "    ):\n",
    "        self.training_sets, self.param_validation_set = sample_datasets(n_datasets=T)\n",
    "        self.entire_dataset = DataSet(train_X, train_y, np.arange(len(train_X)))\n",
    "        self.model_validation_dataset = DataSet(valid_X, valid_y, None)\n",
    "        self.n_generations = n_generations\n",
    "        self.verbose = verbose\n",
    "        self.M = M\n",
    "        self.n_workers = n_workers\n",
    "\n",
    "    def _train(self):\n",
    "        \n",
    "        sample_scores = np.zeros(\n",
    "            (len(self.training_sets), len(self.entire_dataset.X))\n",
    "        )  # sample_scores[model_id][sample] = model's uncertainty of this sample\n",
    "        model_validation_scores = np.zeros(len(self.training_sets))\n",
    "        model_params = list()\n",
    "        \n",
    "\n",
    "        print(\"Multiprocess training...\")\n",
    "        with Pool(processes=4) as pool:\n",
    "            models = pool.map(_train_one, zip(self.training_sets, [self.param_validation_set] * len(self.training_sets)))\n",
    "            \n",
    "        print(\"Synchronization...\")    \n",
    "        for model_id, (ds, model) in self._progress(\n",
    "                enumerate(zip(self.training_sets, models)), total=len(self.training_sets)\n",
    "        ):\n",
    "#             model = train_svr(ds, self.param_validation_set)\n",
    "            preds = model.predict(self.entire_dataset.X)\n",
    "            sample_scores[model_id] = np.abs(self.entire_dataset.y - preds)\n",
    "            preds = model.predict(self.model_validation_dataset.X)\n",
    "            model_validation_scores[model_id] = r2_score(self.model_validation_dataset.y, preds)\n",
    "            model_params.append(model.get_params())\n",
    "        return np.mean(sample_scores * model_validation_scores.reshape((-1,1)), axis=0), model_params, model_validation_scores\n",
    "    \n",
    "    def _select_sets(self, model_validation_scores: np.array):\n",
    "        normalized_scores = model_validation_scores / np.sum(model_validation_scores)\n",
    "        sorted_order = np.argsort(-normalized_scores)  # sort by DESCENDING SCORE\n",
    "        self.training_sets = list(np.array(self.training_sets)[sorted_order])\n",
    "        cum_scores = np.cumsum(normalized_scores[sorted_order])\n",
    "        fitness_threshold = 0.\n",
    "        while fitness_threshold < cum_scores[1]:\n",
    "            fitness_threshold = np.random.random()\n",
    "        fit_datasets = [\n",
    "            ds for ds, is_fit \n",
    "            in zip(self.training_sets, cum_scores < fitness_threshold) \n",
    "            if is_fit\n",
    "        ]\n",
    "        return fit_datasets  # sorted by model score, descending\n",
    "    \n",
    "    def _crossover(self, fit_datasets: List[np.array]):\n",
    "        new_datasets = []\n",
    "        while len(new_datasets) < len(self.training_sets):\n",
    "            # if there is a really small number of fit_datasets, \n",
    "            # we want to resample T new datasets from what we have\n",
    "            for ds1, ds2 in combinations(fit_datasets, 2):\n",
    "                new_datasets.append(DataSet.combine(ds1, ds2))\n",
    "                if len(new_datasets) >= len(self.training_sets):\n",
    "                    break\n",
    "        self.training_sets = new_datasets\n",
    "        \n",
    "    def _mutate(self, sample_scores):\n",
    "        new_datasets = []\n",
    "        for ds in self.training_sets:\n",
    "            ids = np.random.permutation(len(ds.X))\n",
    "            num_of_dumped = ceil(len(ds.X) * self.M)\n",
    "            chosen = ids[:-num_of_dumped]\n",
    "            supplied = ds.ids[chosen]\n",
    "            while len(np.intersect1d(ds.ids[chosen], supplied)) != 0:\n",
    "                supplied = np.random.choice(np.arange(len(self.entire_dataset.X)), size=num_of_dumped, replace=False, p=sample_scores)\n",
    "            new = DataSet(\n",
    "                np.concatenate([ds.X[chosen], self.entire_dataset.X[supplied]]),\n",
    "                np.concatenate([ds.y[chosen], self.entire_dataset.y[supplied]]),\n",
    "                np.concatenate([ds.ids[chosen], supplied])\n",
    "            )\n",
    "            new_datasets.append(new)\n",
    "        self.training_sets = new_datasets\n",
    "            \n",
    "                \n",
    "    def __iter__(self):\n",
    "        self.generation = 0\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.generation >= self.n_generations:\n",
    "            raise StopIteration()\n",
    "        weighted_sample_scores, model_params, model_validation_scores = self._train()\n",
    "        fit_datasets = self._select_sets(model_validation_scores)\n",
    "        \n",
    "        self._crossover(fit_datasets)\n",
    "        probs = make_probabilities(weighted_sample_scores)\n",
    "        print(\"Data probabilities variance:\", probs[probs != 0].var())\n",
    "        self._mutate(probs)\n",
    "        self.generation += 1\n",
    "        return model_validation_scores, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution: 100%|██████████| 16/16 [03:43<00:00, 13.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0026838313604056e-10 0.0\n",
      "49933\n",
      "0.051391845372352724\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution: 100%|██████████| 16/16 [02:58<00:00, 11.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.004530959540358e-10 0.0\n",
      "49887\n",
      "0.08537930619821889\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution: 100%|██████████| 16/16 [02:24<00:00,  8.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0056973689391041e-10 0.0\n",
      "49858\n",
      "0.10584387380374208\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution: 100%|██████████| 16/16 [02:06<00:00,  7.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0065027476283638e-10 0.0\n",
      "49838\n",
      "0.11956100139107564\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution: 100%|██████████| 16/16 [01:59<00:00,  7.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0066236612394062e-10 0.0\n",
      "49835\n",
      "0.12111176123127099\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution: 100%|██████████| 16/16 [02:22<00:00,  8.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0071475906625387e-10 0.0\n",
      "49822\n",
      "0.1304246397047065\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution: 100%|██████████| 16/16 [02:12<00:00,  9.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0073895103270418e-10 0.0\n",
      "49816\n",
      "0.13468358043164008\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution: 100%|██████████| 16/16 [02:13<00:00,  9.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0075104964394579e-10 0.0\n",
      "49813\n",
      "0.13617070567256545\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution: 100%|██████████| 16/16 [02:24<00:00,  8.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0077121821091044e-10 0.0\n",
      "49808\n",
      "0.1402041199047943\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution: 100%|██████████| 16/16 [02:08<00:00,  8.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0078332235725502e-10 0.0\n",
      "49805\n",
      "0.14183004073628386\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution: 100%|██████████| 16/16 [02:18<00:00,  8.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0081156787092237e-10 0.0\n",
      "49798\n",
      "0.14675690840698627\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution: 100%|██████████| 16/16 [02:25<00:00,  8.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0081963661235023e-10 0.0\n",
      "49796\n",
      "0.14868264911565005\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution: 100%|██████████| 16/16 [02:14<00:00,  8.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0080753092202038e-10 0.0\n",
      "49799\n",
      "0.14604526052423927\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution: 100%|██████████| 16/16 [02:22<00:00,  9.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0081963806427094e-10 0.0\n",
      "49796\n",
      "0.1481418298542892\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution: 100%|██████████| 16/16 [02:26<00:00,  9.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0080752861961063e-10 0.0\n",
      "49799\n",
      "0.1464605770859853\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution: 100%|██████████| 16/16 [02:19<00:00,  8.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0082770354865228e-10 0.0\n",
      "49794\n",
      "0.1496798833617404\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution: 100%|██████████| 16/16 [02:17<00:00,  8.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0083981230732397e-10 0.0\n",
      "49791\n",
      "0.15176874844136484\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution: 100%|██████████| 16/16 [02:08<00:00,  7.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0085596583720271e-10 0.0\n",
      "49787\n",
      "0.1543653599516722\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution: 100%|██████████| 16/16 [02:12<00:00,  7.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0083981681612976e-10 0.0\n",
      "49791\n",
      "0.15224168065245197\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolution: 100%|██████████| 16/16 [02:21<00:00,  8.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0084385355562732e-10 0.0\n",
      "49790\n",
      "0.15228560592654664\n"
     ]
    }
   ],
   "source": [
    "ev = Evolution(n_generations=20, verbose=True)\n",
    "history = []\n",
    "data = []\n",
    "for scores, sample_probs in ev:\n",
    "    print(\"Number of samples chosen to resample datasets:\", len(sample_probs[sample_probs != 0]))\n",
    "    history.append(scores)\n",
    "    data.append(sample_probs)\n",
    "    print(\"Mean model score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([6.123e+03, 5.272e+03, 4.444e+03, 4.124e+03, 3.688e+03, 3.073e+03,\n",
       "        2.798e+03, 2.555e+03, 2.019e+03, 1.933e+03, 1.610e+03, 1.490e+03,\n",
       "        1.246e+03, 1.076e+03, 9.630e+02, 8.840e+02, 7.400e+02, 6.520e+02,\n",
       "        5.790e+02, 4.990e+02, 4.570e+02, 4.340e+02, 3.470e+02, 2.940e+02,\n",
       "        2.920e+02, 2.460e+02, 2.270e+02, 1.910e+02, 1.670e+02, 1.560e+02,\n",
       "        1.500e+02, 1.300e+02, 1.220e+02, 8.400e+01, 9.700e+01, 7.400e+01,\n",
       "        6.800e+01, 5.000e+01, 4.100e+01, 4.000e+01, 3.800e+01, 3.800e+01,\n",
       "        4.200e+01, 3.500e+01, 3.200e+01, 2.100e+01, 2.500e+01, 2.100e+01,\n",
       "        3.000e+00, 1.600e+01, 9.000e+00, 1.100e+01, 7.000e+00, 1.200e+01,\n",
       "        8.000e+00, 8.000e+00, 8.000e+00, 7.000e+00, 5.000e+00, 5.000e+00,\n",
       "        1.000e+01, 3.000e+00, 2.000e+00, 5.000e+00, 2.000e+00, 2.000e+00,\n",
       "        5.000e+00, 1.000e+00, 4.000e+00, 2.000e+00, 1.000e+00, 2.000e+00,\n",
       "        1.000e+00, 2.000e+00, 1.000e+00, 4.000e+00, 3.000e+00, 0.000e+00,\n",
       "        1.000e+00, 0.000e+00, 2.000e+00, 1.000e+00, 0.000e+00, 2.000e+00,\n",
       "        2.000e+00, 0.000e+00, 3.000e+00, 2.000e+00, 4.000e+00, 8.000e+00,\n",
       "        7.000e+00, 3.000e+00, 1.000e+01, 5.000e+00, 3.000e+00, 5.000e+00,\n",
       "        3.000e+00, 7.000e+00, 9.000e+00, 4.000e+00]),\n",
       " array([1.99832263e-05, 1.99894435e-05, 1.99956608e-05, 2.00018780e-05,\n",
       "        2.00080953e-05, 2.00143125e-05, 2.00205298e-05, 2.00267470e-05,\n",
       "        2.00329642e-05, 2.00391815e-05, 2.00453987e-05, 2.00516160e-05,\n",
       "        2.00578332e-05, 2.00640505e-05, 2.00702677e-05, 2.00764850e-05,\n",
       "        2.00827022e-05, 2.00889195e-05, 2.00951367e-05, 2.01013540e-05,\n",
       "        2.01075712e-05, 2.01137884e-05, 2.01200057e-05, 2.01262229e-05,\n",
       "        2.01324402e-05, 2.01386574e-05, 2.01448747e-05, 2.01510919e-05,\n",
       "        2.01573092e-05, 2.01635264e-05, 2.01697437e-05, 2.01759609e-05,\n",
       "        2.01821782e-05, 2.01883954e-05, 2.01946126e-05, 2.02008299e-05,\n",
       "        2.02070471e-05, 2.02132644e-05, 2.02194816e-05, 2.02256989e-05,\n",
       "        2.02319161e-05, 2.02381334e-05, 2.02443506e-05, 2.02505679e-05,\n",
       "        2.02567851e-05, 2.02630024e-05, 2.02692196e-05, 2.02754368e-05,\n",
       "        2.02816541e-05, 2.02878713e-05, 2.02940886e-05, 2.03003058e-05,\n",
       "        2.03065231e-05, 2.03127403e-05, 2.03189576e-05, 2.03251748e-05,\n",
       "        2.03313921e-05, 2.03376093e-05, 2.03438266e-05, 2.03500438e-05,\n",
       "        2.03562610e-05, 2.03624783e-05, 2.03686955e-05, 2.03749128e-05,\n",
       "        2.03811300e-05, 2.03873473e-05, 2.03935645e-05, 2.03997818e-05,\n",
       "        2.04059990e-05, 2.04122163e-05, 2.04184335e-05, 2.04246508e-05,\n",
       "        2.04308680e-05, 2.04370852e-05, 2.04433025e-05, 2.04495197e-05,\n",
       "        2.04557370e-05, 2.04619542e-05, 2.04681715e-05, 2.04743887e-05,\n",
       "        2.04806060e-05, 2.04868232e-05, 2.04930405e-05, 2.04992577e-05,\n",
       "        2.05054750e-05, 2.05116922e-05, 2.05179094e-05, 2.05241267e-05,\n",
       "        2.05303439e-05, 2.05365612e-05, 2.05427784e-05, 2.05489957e-05,\n",
       "        2.05552129e-05, 2.05614302e-05, 2.05676474e-05, 2.05738647e-05,\n",
       "        2.05800819e-05, 2.05862992e-05, 2.05925164e-05, 2.05987336e-05,\n",
       "        2.06049509e-05]),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "probs = data[0][data[0] != 0]\n",
    "print(len(probs))\n",
    "plt.hist(probs, bins=100, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"scores_first_ok.json\", 'w') as f:\n",
    "    json.dump([float(s) for s in scores], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
