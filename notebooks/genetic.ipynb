{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic search approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.load('../data/train_X.npy')\n",
    "train_y = np.load('../data/train_y.npy')\n",
    "valid_X = np.load('../data/valid_X.npy')\n",
    "valid_y = np.load('../data/valid_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1500  # dataset size\n",
    "T = 20  # number of datasets per generation\n",
    "M = 0.1  # fraction of dataset samples dropped during mutation phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class DataSet(object):\n",
    "    X: np.array\n",
    "    y: np.array\n",
    "\n",
    "def sample_datasets(\n",
    "        n_samples: int=N, \n",
    "        n_datasets: int=T, \n",
    "        n_validation_samples: int=10*N, \n",
    "        source_X: np.array=train_X, \n",
    "        source_y: np.array=train_y\n",
    ") -> Tuple[List[DataSet], DataSet]:\n",
    "    ids = [\n",
    "        np.random.choice(\n",
    "            len(source_X), \n",
    "            n_samples, \n",
    "            replace=False\n",
    "        ) for i in range(n_datasets)\n",
    "    ]\n",
    "    rest_ids = np.array(list(set(range(len(source_X))) - set(list(np.concatenate(ids)))))\n",
    "    validation_ids = np.random.choice(rest_ids, n_validation_samples)\n",
    "    return [DataSet(source_X[i], source_y[i]) for i in ids], DataSet(source_X[validation_ids], source_y[validation_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "params_dict = {\n",
    "    'kernel': ['rbf'],\n",
    "    'gamma': [1 / i for i in range(80, 130, 10)],\n",
    "    'C': [0.9, 1.0, 1.1],\n",
    "    'epsilon': [1e-3, 3e-3, 1e-2, 3e-2, 1e-1, 3e-1],\n",
    "    'shrinking': [True]\n",
    "}\n",
    "\n",
    "def train_svr(train_set: DataSet, param_validation_set: DataSet, params_dict: dict=params_dict, n_iter: int=20):\n",
    "    ps = ParameterSampler(n_iter=n_iter, param_distributions=params_dict)\n",
    "    scores = np.zeros(n_iter)\n",
    "    models = list()\n",
    "    for idx, params in enumerate(ps):\n",
    "        svr = SVR(**params)\n",
    "        svr.fit(train_set.X, train_set.y)\n",
    "        preds = svr.predict(param_validation_set.X)\n",
    "        scores[idx] = r2_score(param_validation_set.y, preds)\n",
    "        models.append(svr)\n",
    "    return models[np.argmax(scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class VerboseMixin(object):\n",
    "    def _progress(self, iterator, total):\n",
    "        if self.verbose:\n",
    "            return tqdm(iterator, total=total, desc=self.__class__.__name__)\n",
    "        else:\n",
    "            return iterator\n",
    "\n",
    "    def _log(self, message):\n",
    "        if self.verbose:\n",
    "            print(f\"[{self.__class__.__name__}] {message}\")\n",
    "\n",
    "class Evolution(VerboseMixin):\n",
    "    def __init__(\n",
    "            self, \n",
    "            T=T, \n",
    "            train_X=train_X, \n",
    "            train_y=train_y, \n",
    "            valid_X=valid_X, \n",
    "            valid_y=valid_y, \n",
    "            n_generations: int=100,\n",
    "            verbose: bool=False\n",
    "    ):\n",
    "        self.training_sets, self.param_validation_set = sample_datasets(T)\n",
    "        self.entire_dataset = DataSet(train_X, train_y)\n",
    "        self.model_validation_dataset = DataSet(valid_X, valid_y)\n",
    "        self.n_generations = n_generations\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def _train(self):\n",
    "        sample_scores = np.zeros(\n",
    "            (len(self.training_sets), len(self.entire_dataset.X))\n",
    "        )  # sample_scores[model_id][sample] = model's uncertainty of this sample\n",
    "        model_validation_scores = np.zeros(len(self.training_sets))\n",
    "        model_params = list()\n",
    "        for model_id, ds in self._progress(\n",
    "                enumerate(self.training_sets), total=len(self.training_sets)\n",
    "        ):\n",
    "            model = train_svr(ds, self.param_validation_set)\n",
    "            preds = model.predict(self.entire_dataset.X)\n",
    "            sample_scores[model_id] = np.abs(self.entire_dataset.y - preds)\n",
    "            preds = model.predict(self.model_validation_dataset.X)\n",
    "            model_validation_scores[model_id] = r2_score(self.model_validation_dataset.y, preds)\n",
    "            model_params.append(model.get_params())\n",
    "        return np.mean(sample_scores * model_validation_scores.reshape((-1,1)), axis=0), model_params, model_validation_scores\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.generation = 0\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.generation >= self.n_generations:\n",
    "            raise StopIteration()\n",
    "        weighted_sample_scores, model_params, model_validation_scores = self._train()\n",
    "        self.generation += 1\n",
    "        return model_validation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.93444112e-01 -1.77103082e-01  8.38956020e-03  5.37983506e-03\n",
      " -3.11891474e-03 -1.05870403e-04 -9.37304797e-02 -1.68101538e-02\n",
      " -1.24521524e-01  1.11805802e-02 -4.88779576e-01 -3.64735847e-01\n",
      " -5.32156671e-02 -2.40628035e-01 -1.42374381e-01 -4.30398633e-01\n",
      " -3.12083635e-02 -4.24948952e-02 -1.22556100e+00 -1.54009001e-01]\n"
     ]
    }
   ],
   "source": [
    "ev = Evolution(n_generations=1, verbose=True)\n",
    "for scores in ev:\n",
    "    print(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
