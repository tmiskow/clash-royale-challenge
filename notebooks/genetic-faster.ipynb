{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from numba import jit\n",
    "\n",
    "from typing import NamedTuple, List, Tuple\n",
    "\n",
    "np.random.seed(420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from itertools import repeat\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Naming:\n",
    "- *_ids = array of number corresponding to rows in the dataset\n",
    "- *_index = boolean array allowing for fast selection from the dataset\n",
    "\"\"\"\n",
    "\n",
    "class DataSet(NamedTuple):\n",
    "    X: np.array  # (n_samples, n_features)\n",
    "    y: np.array  # 1d\n",
    "    ids: np.array  # 1d\n",
    "\n",
    "class GenerationParams(NamedTuple):\n",
    "    n_models: int  # = n datasets\n",
    "    n_fits: int  # per each model during hyperparameter optimization\n",
    "    train_data: DataSet\n",
    "    n_train_samples: int\n",
    "    train_probs: np.array\n",
    "    valid_data: DataSet\n",
    "    valid_index: np.array\n",
    "        \n",
    "class FitResult(NamedTuple):\n",
    "    train_index: np.array\n",
    "    sample_scores: np.array\n",
    "    model_score: float\n",
    "    model_params: dict\n",
    "        \n",
    "class GenerationResult(NamedTuple):\n",
    "    train_probs: np.array\n",
    "    train_index: np.array  # (n_samples), True for samples that were used in any of the models\n",
    "    model_scores: np.array\n",
    "    model_params: List[dict]\n",
    "    model_samples: np.array  # (n_models, n_train_samples) - IDs, NOT INDEX\n",
    "    \n",
    "class EvolutionParams(NamedTuple):\n",
    "    n_models: int  # = datasets per generation\n",
    "    n_fits: int  # per each model during hyperparameter optimization\n",
    "    n_generations: int\n",
    "    n_train_samples: int\n",
    "    n_valid_samples: int\n",
    "    mutation_prob: float  # between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(n_samples: int, ids: np.array, weights: np.array=None) -> np.array:\n",
    "    selected_ids = np.random.choice(ids, n_samples, replace=False, p=weights)\n",
    "    selected_index = np.isin(ids, selected_ids, assume_unique=True)\n",
    "    return selected_index  # same shape as ids, for easier selection\n",
    "\n",
    "params_dict = {\n",
    "    'kernel': ['rbf'],\n",
    "    'gamma': [1 / i for i in range(80, 130, 10)],\n",
    "    'C': [0.9, 1.0, 1.1],\n",
    "    'epsilon': [1e-3, 3e-3, 1e-2, 3e-2, 1e-1, 3e-1],\n",
    "    'shrinking': [True]\n",
    "}\n",
    "\n",
    "def fit_svr(X_train: np.array, y_train: np.array, X_valid: np.array, y_valid: np.array, params_dict: dict=params_dict, n_iter: int=25):\n",
    "    ps = ParameterSampler(n_iter=n_iter, param_distributions=params_dict)\n",
    "    scores = np.zeros(n_iter)\n",
    "    models = list(repeat(None, n_iter))\n",
    "    for idx, params in enumerate(ps):\n",
    "        svr = SVR(**params)\n",
    "        svr.fit(X_train, y_train)\n",
    "        scores[idx] = r2_score(y_valid, svr.predict(X_valid))\n",
    "        models[idx] = svr\n",
    "    return models[np.argmax(scores)]\n",
    "\n",
    "\n",
    "def fit_model(params: GenerationParams) -> FitResult:\n",
    "    train_index = sample(\n",
    "        params.n_train_samples, \n",
    "        params.train_data.ids, \n",
    "        params.train_probs\n",
    "    )\n",
    "    model = fit_svr(\n",
    "        params.train_data.X[train_index], \n",
    "        params.train_data.y[train_index],\n",
    "        params.valid_data.X[params.valid_index],\n",
    "        params.valid_data.y[params.valid_index],\n",
    "        n_iter=params.n_fits\n",
    "    )\n",
    "    sample_scores = np.power(\n",
    "        params.train_data.y - model.predict(params.train_data.X),\n",
    "        2\n",
    "    )\n",
    "    model_score = r2_score(\n",
    "        params.valid_data.y[params.valid_index],\n",
    "        model.predict(params.valid_data.X[params.valid_index])\n",
    "    )\n",
    "    return FitResult(train_index, sample_scores, model_score, model.get_params())\n",
    "\n",
    "def run_generation(params: GenerationParams, n_models: int, pool: mp.Pool) -> Tuple[np.array, np.array, np.array, GenerationResult]:\n",
    "    train_probs = np.zeros_like(params.train_probs)\n",
    "    used_train_index = np.zeros_like(params.train_data.y, dtype=np.bool)\n",
    "    model_params = list(repeat({}, params.n_models))\n",
    "    model_scores = np.zeros(params.n_models)\n",
    "    model_samples = np.zeros((params.n_models, params.n_train_samples))\n",
    "    results = pool.map(fit_model, repeat(params, n_models))\n",
    "#     results = map(fit_model, repeat(params, n_models))  # in case the Pool does not work in Jupyter\n",
    "    for idx, fit_result in enumerate(results):\n",
    "        used_train_index |= fit_result.train_index\n",
    "        train_probs += fit_result.sample_scores * np.exp(fit_result.model_score)\n",
    "        model_params[idx] = fit_result.model_params\n",
    "        model_scores[idx] = fit_result.model_score\n",
    "        model_samples[idx] = params.train_data.ids[fit_result.train_index].astype(np.uint)\n",
    "    return GenerationResult(train_probs, used_train_index, model_scores, model_params, model_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evolution(train_data: DataSet, valid_data: DataSet, pool: mp.Pool, params: EvolutionParams):\n",
    "    valid_index = sample(params.n_valid_samples, valid_data.ids)\n",
    "    train_probs = np.ones(len(train_data.ids)) / len(train_data.ids)\n",
    "    results = []\n",
    "    with trange(params.n_generations) as t:\n",
    "        for generation_idx in t:\n",
    "            t.set_description(f\"Generation {generation_idx+1}\")\n",
    "            gen_results = run_generation(\n",
    "                GenerationParams(\n",
    "                    params.n_models,\n",
    "                    params.n_fits,\n",
    "                    train_data,\n",
    "                    params.n_train_samples,\n",
    "                    train_probs,\n",
    "                    valid_data,\n",
    "                    valid_index\n",
    "                ),\n",
    "                params.n_models,\n",
    "                pool\n",
    "            )\n",
    "            # we simulate selecting samples for mutation by altering their probabilities:\n",
    "            gen_train_probs = gen_results.train_probs\n",
    "            gen_results.train_probs[gen_results.train_index] *= (1. - params.mutation_prob)\n",
    "            gen_train_probs[~gen_results.train_index] *= params.mutation_prob\n",
    "            train_probs += gen_train_probs\n",
    "            train_probs /= sum(train_probs)\n",
    "            results.append(gen_results)\n",
    "            t.set_postfix(mean_score=sum(gen_results.model_scores)/len(gen_results.model_scores), max_score=max(gen_results.model_scores))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing actual evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.load('../data/train_X.npy')\n",
    "train_y = np.load('../data/train_y.npy')\n",
    "valid_X = np.load('../data/valid_X.npy')\n",
    "valid_y = np.load('../data/valid_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataSet(train_X, train_y, np.arange(len(train_X)))\n",
    "valid_data = DataSet(valid_X, valid_y, np.arange(len(valid_X)) * (-1))\n",
    "pool = mp.Pool(4)\n",
    "params = EvolutionParams(\n",
    "    n_models = 16,\n",
    "    n_fits = 16,\n",
    "    n_generations = 2,\n",
    "    n_train_samples = 1500,\n",
    "    n_valid_samples = 6000,\n",
    "    mutation_prob = 0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation 2: 100%|████████████████████████████████| 2/2 [17:24<00:00, 523.52s/it, max_score=-.194, mean_score=-.44]\n"
     ]
    }
   ],
   "source": [
    "results = run_evolution(train_data, valid_data, pool, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfix_imports\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Write a pickled representation of obj to the open file object file.\n",
       "\n",
       "This is equivalent to ``Pickler(file, protocol).dump(obj)``, but may\n",
       "be more efficient.\n",
       "\n",
       "The optional *protocol* argument tells the pickler to use the given\n",
       "protocol supported protocols are 0, 1, 2, 3 and 4.  The default\n",
       "protocol is 3; a backward-incompatible protocol designed for Python 3.\n",
       "\n",
       "Specifying a negative protocol version selects the highest protocol\n",
       "version supported.  The higher the protocol used, the more recent the\n",
       "version of Python needed to read the pickle produced.\n",
       "\n",
       "The *file* argument must have a write() method that accepts a single\n",
       "bytes argument.  It can thus be a file object opened for binary\n",
       "writing, an io.BytesIO instance, or any other custom object that meets\n",
       "this interface.\n",
       "\n",
       "If *fix_imports* is True and protocol is less than 3, pickle will try\n",
       "to map the new Python 3 names to the old module names used in Python\n",
       "2, so that the pickle data stream is readable with Python 2.\n",
       "\u001b[1;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?pickle.dump"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
